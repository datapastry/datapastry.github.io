---
title: "How to hire a data scientist"
author: Iskander Yusof
excerpt: "It takes one to know one."
header:
  overlay_image: /assets/images/header-pastry.jpg
  overlay_filter: 0.6
---
Software engineers often complain about the endless technical tests they have to overcome in order to get hired.

For programmers who are relatively green it’s perhaps understandable that they would be tested heavily, but it’s somewhat galling if you have 10 years’ experience in a domain and get asked to answer basic programming and algorithms problems. You don’t ask an accountant to solve simple arithmetic problems before you allow them to file your taxes.

Anyway, the reason for all the testing is simple. Most programmers are [rubbish at programming](https://blog.codinghorror.com/why-cant-programmers-program/), so you have no choice but to test them extensively if you don’t want to inadvertently hire a smooth-talking knucklehead.

Unfortunately, the same is true of data science. Without testing a prospective hire’s ability to do data science, you’ll have no way of knowing whether they are actually able to do the job.

Most likely you’ll optimise for the ability to _talk_ about data science rather than actually _do_ data science, which is fine if all you want is a great communicator, but not so good if you need results.

When I’m interviewing prospective hires, I’m painfully aware than I can be fooled by someone who uses roughly the right terminology and seems to follow the right kinds of processes.

I always find it interesting to see how candidates respond as I move from generalist “talk me through how you solved that problem”-type questions to more specific technical questions. Often candidates will be able to improvise their way through the generalist questions but come unstuck as soon as they’re asked something very specific.

In general, people are easily fooled by confident, eloquent speakers. It’s easy for a charlatan to make it sound like they know what they’re talking about when they really don’t.

On the flip side, a slightly diffident data scientist might turn out to be exactly the right person for the job.

## Testing data science candidates

When devising a data science test, you can forget about using brainteasers, personality tests or clever questions the interviewer thought up in order to demonstrate their intelligence. Doing well in such tests is a poor predictor of on-the-job performance.

The best way to test a prospective hire is to have them perform work that is as close as possible to the actual role. This is often called a _work sample test_.

The reason for its effectiveness should be obvious: what better way to evaluate a candidate’s suitability for a job than to have them do the job itself?

Coming up with a good work sample test is not easy, however. There are a couple of things you’ll need to take into account:



*   You’ll need to distill the main elements of the job into a test that is short enough to be doable within a short time frame.
    
    We’d suggest focusing on testing things that *can’t* be learnt quickly on the job.
*   You should devise an objective scoring rubric to grade each candidate.
*   You should standardise your test to ensure every candidate is treated in the exact same way. Ideally you should calibrate your scoring using data scientists you’ve worked with before.
    
    As a bare minimum, at least one person should successfully complete the test before you give it to a candidate.
*   Good data science tests typically involve a data task that encompasses exploratory analysis, some cleaning/feature engineering and building a model.
    
    You can also incorporate a system design problem into your task (e.g. “how would you productionise this model to serve predictions to hundreds of users per second?”) if it’s relevant to the job.
*   Try to ensure your test is substantive enough to allow you to gauge the applicant’s code quality. Clean, well-structured code is something many data scientists struggle to achieve. 

**Shameless plug:** We’re putting together a free work sample test and scoring rubric that you can use as a basis for your own test. [Let us know](https://google.com) if you’d like access and we’ll send it over when it’s ready.

We’d suggest allowing candidates to do the test at home instead of insisting that it be conducted in person. This will save time and money for both parties.

If the candidate is successful at the work sample stage, you can invite them over to your office to present their results.

On the subject of time, try to ensure the test can be completed in a maximum of 6 hours by a good candidate. If possible your test should be a lot shorter than this; between 2-4 hours would be ideal. Don’t forget that your candidate will most likely have other tests to do as well.

Senior candidates will also often have families, so they’ll be very constrained for time outside normal working hours. (I _don’t_ have a family, but I also have very little free time. Those pastries don’t just eat themselves.)

Should you pay for the candidate to do the test? This is a tough one. It’s not the norm in industry for candidates to get paid to do tests, but I wouldn’t be surprised if this changes given current trends.

Morally I’d say you _should_ pay for a candidate’s time, but I’ve never actually been paid to do a test before. For me, the benefit of securing a good job is worth the small investment of time. I also enjoy working on interesting, challenging tests, so do try to make sure your test isn’t as dull as dishwater.

Unless, of course, the job itself is boring, in which case it’s probably for the best if your candidate knows what to expect.

Encourage candidates to use the same resources that they’d use on the job and keep an open channel for any questions they might have. You wouldn’t refuse to answer questions in a real job situation, so it doesn’t make sense to create arbitrary restrictions during your testing phase.

Make sure each candidate knows how long it will take for their submission to be graded and stick to this timeline. Speaking of which...

### Being nice

Try not to annoy prospective hires by demanding things that aren’t really necessary. From a human perspective, I shouldn’t need to explain further the importance of being nice.

But even if you’re a callous employer with a block of ice where your heart is meant to be, it’s still in your interest to be nice. Demand massively outstrips supply for good data scientists -- within reason, we don’t have difficulty getting the kinds of packages we want.

Here are a couple of things that _should_ be no-brainers, but very rarely are:



*   Right from the start, clearly communicate to the candidate your hiring process from CV review through to offer.
    
    All you need for this is a simple timeline indicating each stage of the process and who the candidate will be talking to. **Ensure you stick to your timeline.**
*   Realistically HR will get involved with your hiring process at some point. Again, set expectations for candidates so they won’t be surprised if HR throws up a few roadblocks (we’ve all been there!).
*   Don’t use a work sample test to get candidates to do real work for free. The data science community is fairly small and nobody will want to work with you again if you do this.

If your hiring process is very unpleasant, many good candidates will just walk away instead of wasting time and energy with your company. There are plenty of other data science jobs out there.

And if you’re happy with a candidate, **make a serious offer as fast as you possibly can.**

I can’t emphasise this enough. I don’t want to boast (he lied), but I’ve never been turned down for a job once I’ve spoken to a real person. I also don’t like to waste time, so I simply take the first good offer I receive.

Generally I do this out of a (possibly irrational) fear that I’ll lose the offer if I hang around for too long. I’m pretty sure a lot of data scientists are the same way, so you can save yourself a bunch of time and money just by making hiring decisions more quickly than your competitors.

### Don’t copy Google

It’s quite common for companies to cite Google or some other hugely successful tech company as inspiration for their hiring practices. After all, Google is known for having outstanding employees, so surely it would make sense to learn from how they hire?

Unfortunately, what works for Google almost certainly won’t work for you. Because, well, you’re not Google.

All hiring processes are fundamentally a tradeoff between _false positives_ and _false negatives_. A false positive is an accidental hire of a bad candidate. A false negative is a rejection of a candidate you should have hired.

A super-high interviewing bar means that you’ll have very few false positives but also a lot of false negatives. You’ll reject a lot of great candidates, but the few people you do hire will likely be excellent.

On the other hand, a low interviewing bar means that you’ll accept a lot of dodgy candidates… and then you’ll either have to put up with incompetent employees or fire people regularly. Also not good.

Google-style interviews are intended to minimise false positives: they really, really don’t want to inadvertently hire a dud candidate. For this reason, they have a very low acceptance rate and reject a lot of people they “should” have hired.

So why not do the same as Google? There are two reasons for this:



*   Everyone wants to work at Google. They have a huge pool of candidates to draw from so even if they reject 99% of them, they’ll still be left with a sizeable number of people.
*   Google pays for the privilege of being so selective. Do you pay as well as Google? Is your company as prestigious as Google? If not, perhaps you should reconsider being as selective as Google.

Of course, this doesn’t mean you should be OK with false positives and accept mediocre candidates. It just means you can’t afford to have an interview process where you reject huge numbers of qualified people. Your hiring process needs to minimise both false positives and false negatives.

Yes, that’s right. **You need to be better at hiring than Google.** It’s actually not that hard, because Google is optimising for something different from you.

## Writing a job description

A good job description for a data science role is not much different from any other technical role. Things you’ll need to cover:



*   A description of your company and team/department
*   An overview of responsibilities for the role
*   Hard requirements for the applicant
*   Nice-to-haves
*   Salary, benefits and other perks

Employers have the unfortunate tendency to list far more skills than they need as “required” for data science roles.

Almost all the jobs I’ve worked in over the last 3 years have specified deep learning as a hard requirement. For the most part, the subject never comes up again during either the interviews or the jobs themselves. (Interestingly, few job descriptions ever mention “data munging skills” as a hard requirement...)

This is so common that I view it as a minor annoyance rather than a dealbreaker, but it doesn’t give a particularly good first impression for a company.

And not every applicant will realise that your “hard requirements” aren’t actually requirements. You’ll scare off both good and bad candidates by writing an inaccurate job description, so just honestly state what the job involves and don’t exaggerate.

If you really do think writing JavaScript might be part of a candidate’s responsibilities in the future, put this down as a nice-to-have and use it as a tiebreaker in an “all other things are equal” situation.

It’s really nice if you say what a “day in the life of a data scientist” would be like at your company. An experienced candidate should ask about this anyway, of course; there’s very little consistency between data science operations in different companies.

Without this knowledge, accepting a new role can feel a bit like walking across a motorway with your eyes closed in the hope of finding a pastry on the other side.

**Hey, it’s time for another shameless plug!** Remember when we said we’re putting together a free work sample test and scoring rubric just for you? We’ll also create a sample job description for you to use as a template. [Let us know](https://www.google.com/) if you’d like to be notified when these are ready. As always, you’re welcome to customise our materials as much as you like.

## What skills and experience should you expect from a data scientist?

Data scientists are the ultimate jacks of all trades.

You don’t need someone who’s an expert in everything but it’s important that they understand how all the pieces fit together. **This is not a good field for extreme specialists**.

We’d advise customising the skills you test based on the specific role for which you’re hiring. You probably don’t need a data scientist with a deep knowledge of convolutional neural networks if they’re mostly going to be working on credit scoring.

Still, there are more similarities than differences in data science roles. Below you can find the types of skills and experience we’ve found to be especially relevant.

This is not intended to be an exhaustive list, nor should you expect to find a data scientist who ticks all these boxes. Again, we’d recommend tailoring your test based on what is genuinely important for your specific role.


*   **Machine Learning**
    *   Knowledge of supervised learning (regression, classification) and unsupervised learning (clustering, dimensionality reduction) techniques
        *   Linear Regression, Naive Bayes, Decision Trees, Logistic Regression, SVM, k-NN, k-means, Random Forests, Gradient Boosted Trees, PCA, Gaussian Mixture Models...
    *   Being able to explain in depth how at least one ML model works
    *   Exploratory data analysis: what’s their approach?
    *   Building a model: what’s their approach?
    *   Feature selection/extraction
    *   Training, test, validation sets
    *   Cross-validation and bootstrapping
    *   How to assess the accuracy of an ML model
    *   Online and offline evaluation of ML models
    *   Can they relate ML-specific metrics to business metrics?
    *   Curse of dimensionality
    *   Overfitting
    *   Handling missing data
    *   Handling lots of observations/features
    *   Handling outliers
    *   Handling data quality issues: what’s their approach?
    *   Handling big data (too big to fit in memory): what’s their approach?
    *   Data wrangling/munging: how happy are they to work with messy data and get it into a suitable shape for analytics work?
*   **Tools**
    *   Comfortable with data science libraries such as numpy, pandas, sklearn
    *   Experience with cloud environments like AWS or GCP
    *   Experience with ML as a service (e.g. SageMaker, H2O or Cloud ML)
    *   Experience with relational databases and SQL
    *   Experience with NoSQL data stores like Elasticsearch or Redis
*   **Statistics**
    *   Hypothesis testing, confidence intervals, probability distributions (Gaussian, binomial, Poisson...), transforming distributions, basic probability theory, basic Bayesian statistics, correlation
    *   Measures of central tendency (mean, median, mode...) and dispersion (standard deviation, interquartile range…)
    *   Understanding of possible sources of bias
    *   How to run an A/B test
*   **Algorithms & Data Structures**
    *   Basic algorithms and data structures (sorting, searching, arrays, linked lists, stacks, queues, trees etc)
    *   Algorithmic complexity
    *   Recursion
    *   Dynamic programming
    *   Basic computer architecture (understanding the memory hierarchy, roughly what CPUs do etc)
*   **Maths**
    *   Linear algebra, multivariable calculus, [optimisation](https://en.wikipedia.org/wiki/Mathematical_optimization)
*   **Software Engineering**
    *   Ability to write clean, idiomatic Python
    *   Knowledge of another programming language (ideally a widely-used language very different from Python, such as Java or Scala)
    *   Tests (from “small” unit tests through to “large” integration tests)
    *   Version control
    *   Continuous integration and deployment
    *   An understanding of how to write reasonably efficient code
    *   Model deployment: how to get a machine learning model into production
    *   How much do they know about the kinds of issues you can run into with a productionised ML model? (e.g. drift, model updates, management of multiple models, monitoring accuracy metrics)
*   **Soft Skills**
    *   Verbal and written communication skills: how good are they at communicating technical subjects to a lay audience? **Can they communicate the value of what they do?**
    *   How much emphasis do they place on the tools and techniques they use vs. the business value generated from their work?
    *   **Process and management:**
        *   Experience leading a team/project
        *   Experience working in an agile development environment
        *   Communication/management style
        *   Experience working with different stakeholders when delivering a data science project
    *   **Team structure:**
        *   Have they ever worked in a cross-functional team or have they always worked in pure data science teams?
        *   What has their relationship been with other data scientists, data engineers, data analysts or software engineers?
        *   Do they normally work solo or in close collaboration with others?
*   **Other**
    *   Specific industry experience, e.g. fintech or retail
    *   Specific knowledge of sister fields like NLP or computer vision
    *   Specific knowledge of “advanced” ML and statistical techniques such as deep learning or Bayesian inference

## The whole enchilada

These are steps we’d suggest using when hiring a data scientist. You don’t have to stick to this precisely; the only parts we’d view as being essential are the work sample test and ensuing discussion. 



1. **CV review**

    This is normally pretty easy and shouldn’t take more than a few minutes per CV once you know what to look for. Check the CV against your list of job requirements (which should also be in your job description!).

    If most of the requirements are satisfied, then you can move on to the next stage. Remember that the goal is to filter out obviously-poor candidates, not to identify great candidates at the very first stage.

2. **Phone screen**

    You’ll probably want a further screen to filter out dud candidates before taking the time to send them a work sample test.

    The idea of the phone screen is simply to eliminate candidates who are obviously not up to scratch or won’t be a good fit for some other reason. It’s a timesaving measure for both you and the candidate.

    We’ve found that a mix of questions about experience, a few specific technical questions and a short discussion of the role works well.

3. **Work sample test (ideally take-home)**

    I’m pretty sure I’ve already discussed this. Please scroll up.

    TL; DR version: put together a concise test that’s representative of the job itself. And let us know if you’d like an example of a test and scoring rubric to use as a template.

4. **Presentation and discussion of results**

    No data science task would be complete without a presentation! The goal here should be to test the candidate’s communication skills and dive deeply into any questions you might have about the candidate’s work.

    It also makes it hard for candidates to pay other people to do the test for them.

5. **Technical interview (in person)**

    You usually won’t be able to put everything you want into a work sample test -- at least, not if you want the test to be doable in under 10 years.

    For this reason, you might want to conduct a separate technical interview to examine the applicant’s knowledge of software testing, model deployment and other topics.


    We don’t consider this to be as reliable an indicator as the work sample test, but it can serve as a useful tiebreaker if you have two very similar candidates. It might also be possible to incorporate the technical interview into the discussion of their work sample task.


    For more senior candidates -- especially those that will be leading projects -- the in-person interview is also a good opportunity to see where their priorities lie. Do they optimise for generating business value or are they more interested in technical concerns?


    A good way to assess this is to talk to the candidate about their past projects: do they emphasise the tools and algorithms they used? Or do they focus on the impact of their work?

    Technical acumen doesn’t always go hand in hand with having good business sense.

6. **Culture fit**

    Most data scientists are lovely and personable like us, but you do get the occasional lunatic. So you might want to get an idea of how the candidate will gel with your other team members before making them an offer.

    But make sure you have a clear idea of exactly what it is you mean by "culture fit" (make it part of your rubric!).

    “Didn’t fit the company culture” might just mean that the existing culture is a homogeneous old boys’ club and you'd subconsciously like to keep it that way.


### Keep evolving

Over time, you should be looking to improve your hiring practices so that you do a better job of selecting good candidates.

Realistically you can’t treat this as a data science problem (!) as you won’t have enough data points, but after making a hire it’s worth keeping an eye on how closely their work output corresponds with what you determined from your scoring rubric.

Did you over/underestimate their ability in any particular area? If so, you’ll want to figure out why and update your testing accordingly. 

Unfortunately it’s a lot harder to learn from the people you _didn’t_ hire as you’ll have no way of knowing how they might have performed had you given them the job. (If you have an idea of how to solve this problem, let us know.)

## But I’m not a data scientist!

For some reason lots of non-technical people believe they have the ability to hire good technical candidates.

They’re fooling themselves, unfortunately. The _only_ time I’ve seen this work consistently is when a hiring manager pays over the odds for data scientists with great portfolios.

I’ve been through many non-technical hiring processes as well as technical interviews. With the non-technical interviews, I usually have a strong sense that I could just as easily get the job after reading a few blog articles and saying a few buzzwords.

It also sets off a red flag in my mind: if the company doesn’t have a serious hiring process, what kinds of jokers will I be working with? (The reverse is also true. A good hiring process gives me a lot of confidence in a company.)

So how can you identify a good data scientist if you yourself are not a data scientist?

**Short answer:** You can’t. Your best bet is to hire someone with a great portfolio, but as mentioned this will likely cost you a small fortune because everyone else will want that person as well. It doesn’t take a genius to figure out that someone who used to run data science at Netflix and Airbnb is likely to be a pretty good data scientist.

**Long answer:** You can’t. At least not entirely on your own. You really need to find a way to get assistance from data scientists that you know and trust. If you’re not in a position to do this, then your best bet is to get in touch with us and we’ll happily play the role of “trusted data scientists”.

It’s been too long since the last shameless plug, so I’ll conclude with a couple of paragraphs of marketing fluff.

If you do find yourself needing to hire a good data scientist -- and it _is_ hard! -- then [book a free consultation](https://calendly.com/isk-pastry/consult) and we’ll help you out.

We’ll give you advice on hiring strategy (maybe you [don’t need a data scientist at all]({{ site.baseurl }}{% post_url 2019-08-17-you-dont-need-a-data-scientist %})) and build a structured interview and testing process tailored to your specific needs.

And if that’s not enough, we’ll even supply you with pastries.

Last but not least, we’re putting together a free **Hire a Data Scientist package** containing a sample work sample test (ha), objective scoring rubric and example job description.

You can use this package as a template for your own data science hiring needs. [Let us know](https://www.google.com/) if you’d like us to send the package to you when it's ready.
